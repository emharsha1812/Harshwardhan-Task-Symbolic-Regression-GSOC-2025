{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formulas saved to filenames.txt\n"
     ]
    }
   ],
   "source": [
    "from openpyxl import load_workbook\n",
    "wb = load_workbook('FeynmanEquations.xlsx', data_only=False)\n",
    "ws = wb.active\n",
    "\n",
    "# Iterate through rows (we start from row 2 because we skip header)\n",
    "formula_col_index = 1 \n",
    "formula_list=[]\n",
    "# Iterate through rows (we start from row 2 because we skip header)\n",
    "for row in ws.iter_rows(min_row=2):\n",
    "    # get cell in formula column\n",
    "    cell = row[formula_col_index - 1]  # zero-indexed\n",
    "    formula_list.append(cell.value) \n",
    "    \n",
    "\n",
    "##Save the formula_list in a text file\n",
    "filename = \"filenames.txt\"\n",
    "\n",
    "with open(filename, \"w\") as f:\n",
    "    for formula in formula_list:\n",
    "        f.write(formula + \"\\n\")\n",
    "\n",
    "print(f\"Formulas saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "DATA_END_ID = 4  # replace with the actual token ID for [DATA_END]\n",
    "combined_samples = []\n",
    "\n",
    "# 1) Load RPN file\n",
    "with open(\"formulas_rpn.json\", \"r\") as f:\n",
    "    rpn_data = json.load(f)  # a list of dicts: [{\"id\": \"I.6.2a\", \"rpn\": [...]}, ...]\n",
    "\n",
    "# 2) Load numeric-data file\n",
    "with open(\"dataset_encoded.json\", \"r\") as f:\n",
    "    data_dict = json.load(f) # a dict with keys like \"I.6.2a\" : [ data tokens ], etc.\n",
    "\n",
    "# 3) Combine data & RPN for each entry\n",
    "for item in rpn_data:\n",
    "    formula_id = item[\"id\"]\n",
    "    rpn_tokens = item[\"rpn\"]\n",
    "\n",
    "    # Find matching data tokens (same ID) in data_dict\n",
    "    if formula_id in data_dict:\n",
    "        data_tokens = data_dict[formula_id]\n",
    "        combined = data_tokens + [DATA_END_ID] + rpn_tokens\n",
    "        combined_samples.append(combined)\n",
    "    else:\n",
    "        print(f\"Warning: {formula_id} not found in dataset_encoded.json\")\n",
    "\n",
    "# 'combined_samples' now contains your full sequences, each with data followed by [DATA_END] and formula RPN tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"combined_samples.json\", \"w\") as f:\n",
    "    json.dump(combined_samples, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Problems - Inconsistency in the dataset \n",
    "## In the excel file I.15.1 is there while in the files its labelled as I.15.10\n",
    "## Similary in the files instead of I.48.2 its labelled as I.48.20 which cause inconsitencies in the dataset\n",
    "### Also II.11.17's file is incorrectly labelled as II.11.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input shape: torch.Size([256, 31])\n",
      "Sample target shape: torch.Size([256, 31])\n",
      "Sample mask shape: torch.Size([256, 31])\n",
      "Sample input: tensor([ 647,  968, 1731,    2,  647,  983, 1731,    2,  647,  976])\n",
      "Sample target: tensor([ 968, 1731,    2,  647,  983, 1731,    2,  647,  976, 1731])\n",
      "Max token ID in input: 1733\n",
      "Max token ID in target: 1733\n",
      "[Epoch 1/50] Train Loss: 2.0502 | Train Acc: 0.6656 || Val Loss: 1.8127 | Val Acc: 0.6850\n",
      "  (Best validation loss so far, saving model)\n",
      "[Epoch 2/50] Train Loss: 1.8016 | Train Acc: 0.6849 || Val Loss: 1.7787 | Val Acc: 0.6888\n",
      "  (Best validation loss so far, saving model)\n",
      "[Epoch 3/50] Train Loss: 1.7802 | Train Acc: 0.6889 || Val Loss: 1.7639 | Val Acc: 0.6922\n",
      "  (Best validation loss so far, saving model)\n",
      "[Epoch 4/50] Train Loss: 1.7636 | Train Acc: 0.6928 || Val Loss: 1.7508 | Val Acc: 0.6947\n",
      "  (Best validation loss so far, saving model)\n",
      "[Epoch 5/50] Train Loss: 1.7495 | Train Acc: 0.6951 || Val Loss: 1.7364 | Val Acc: 0.6977\n",
      "  (Best validation loss so far, saving model)\n",
      "[Epoch 6/50] Train Loss: 1.7383 | Train Acc: 0.6971 || Val Loss: 1.7291 | Val Acc: 0.6991\n",
      "  (Best validation loss so far, saving model)\n",
      "[Epoch 7/50] Train Loss: 1.7302 | Train Acc: 0.6983 || Val Loss: 1.7236 | Val Acc: 0.7000\n",
      "  (Best validation loss so far, saving model)\n",
      "[Epoch 8/50] Train Loss: 1.7241 | Train Acc: 0.6995 || Val Loss: 1.7195 | Val Acc: 0.7005\n",
      "  (Best validation loss so far, saving model)\n",
      "[Epoch 9/50] Train Loss: 1.7184 | Train Acc: 0.7002 || Val Loss: 1.7163 | Val Acc: 0.7017\n",
      "  (Best validation loss so far, saving model)\n",
      "[Epoch 10/50] Train Loss: 1.7134 | Train Acc: 0.7010 || Val Loss: 1.7125 | Val Acc: 0.7026\n",
      "  (Best validation loss so far, saving model)\n",
      "[Epoch 11/50] Train Loss: 1.7089 | Train Acc: 0.7017 || Val Loss: 1.7119 | Val Acc: 0.7024\n",
      "  (Best validation loss so far, saving model)\n",
      "[Epoch 12/50] Train Loss: 1.7054 | Train Acc: 0.7023 || Val Loss: 1.7092 | Val Acc: 0.7034\n",
      "  (Best validation loss so far, saving model)\n",
      "[Epoch 13/50] Train Loss: 1.7019 | Train Acc: 0.7026 || Val Loss: 1.7096 | Val Acc: 0.7033\n",
      "[Epoch 14/50] Train Loss: 1.6984 | Train Acc: 0.7032 || Val Loss: 1.7084 | Val Acc: 0.7032\n",
      "  (Best validation loss so far, saving model)\n",
      "[Epoch 15/50] Train Loss: 1.6954 | Train Acc: 0.7036 || Val Loss: 1.7090 | Val Acc: 0.7034\n",
      "[Epoch 16/50] Train Loss: 1.6919 | Train Acc: 0.7040 || Val Loss: 1.7084 | Val Acc: 0.7039\n",
      "[Epoch 17/50] Train Loss: 1.6886 | Train Acc: 0.7045 || Val Loss: 1.7093 | Val Acc: 0.7040\n",
      "[Epoch 18/50] Train Loss: 1.6853 | Train Acc: 0.7048 || Val Loss: 1.7102 | Val Acc: 0.7034\n",
      "[Epoch 19/50] Train Loss: 1.6821 | Train Acc: 0.7050 || Val Loss: 1.7105 | Val Acc: 0.7040\n",
      "[Epoch 20/50] Train Loss: 1.6779 | Train Acc: 0.7055 || Val Loss: 1.7122 | Val Acc: 0.7043\n",
      "[Epoch 21/50] Train Loss: 1.6742 | Train Acc: 0.7059 || Val Loss: 1.7163 | Val Acc: 0.7038\n",
      "[Epoch 22/50] Train Loss: 1.6703 | Train Acc: 0.7061 || Val Loss: 1.7162 | Val Acc: 0.7036\n",
      "[Epoch 23/50] Train Loss: 1.6660 | Train Acc: 0.7068 || Val Loss: 1.7172 | Val Acc: 0.7042\n",
      "[Epoch 24/50] Train Loss: 1.6615 | Train Acc: 0.7069 || Val Loss: 1.7232 | Val Acc: 0.7035\n",
      "[Epoch 25/50] Train Loss: 1.6562 | Train Acc: 0.7074 || Val Loss: 1.7262 | Val Acc: 0.7036\n",
      "[Epoch 26/50] Train Loss: 1.6506 | Train Acc: 0.7080 || Val Loss: 1.7273 | Val Acc: 0.7036\n",
      "[Epoch 27/50] Train Loss: 1.6451 | Train Acc: 0.7083 || Val Loss: 1.7312 | Val Acc: 0.7040\n",
      "[Epoch 28/50] Train Loss: 1.6390 | Train Acc: 0.7089 || Val Loss: 1.7363 | Val Acc: 0.7029\n",
      "[Epoch 29/50] Train Loss: 1.6324 | Train Acc: 0.7093 || Val Loss: 1.7363 | Val Acc: 0.7035\n",
      "[Epoch 30/50] Train Loss: 1.6258 | Train Acc: 0.7100 || Val Loss: 1.7425 | Val Acc: 0.7035\n",
      "[Epoch 31/50] Train Loss: 1.6184 | Train Acc: 0.7106 || Val Loss: 1.7512 | Val Acc: 0.7026\n",
      "[Epoch 32/50] Train Loss: 1.6110 | Train Acc: 0.7112 || Val Loss: 1.7586 | Val Acc: 0.7032\n",
      "[Epoch 33/50] Train Loss: 1.6031 | Train Acc: 0.7120 || Val Loss: 1.7620 | Val Acc: 0.7028\n",
      "[Epoch 34/50] Train Loss: 1.5947 | Train Acc: 0.7126 || Val Loss: 1.7693 | Val Acc: 0.7022\n",
      "[Epoch 35/50] Train Loss: 1.5866 | Train Acc: 0.7135 || Val Loss: 1.7772 | Val Acc: 0.7031\n",
      "[Epoch 36/50] Train Loss: 1.5774 | Train Acc: 0.7142 || Val Loss: 1.7819 | Val Acc: 0.7025\n",
      "[Epoch 37/50] Train Loss: 1.5693 | Train Acc: 0.7147 || Val Loss: 1.7906 | Val Acc: 0.7022\n",
      "[Epoch 38/50] Train Loss: 1.5602 | Train Acc: 0.7155 || Val Loss: 1.7977 | Val Acc: 0.7018\n",
      "[Epoch 39/50] Train Loss: 1.5514 | Train Acc: 0.7164 || Val Loss: 1.8048 | Val Acc: 0.7022\n",
      "[Epoch 40/50] Train Loss: 1.5420 | Train Acc: 0.7173 || Val Loss: 1.8154 | Val Acc: 0.7021\n",
      "[Epoch 41/50] Train Loss: 1.5334 | Train Acc: 0.7180 || Val Loss: 1.8220 | Val Acc: 0.7020\n",
      "[Epoch 42/50] Train Loss: 1.5242 | Train Acc: 0.7188 || Val Loss: 1.8368 | Val Acc: 0.7017\n",
      "[Epoch 43/50] Train Loss: 1.5150 | Train Acc: 0.7197 || Val Loss: 1.8401 | Val Acc: 0.7019\n",
      "[Epoch 44/50] Train Loss: 1.5061 | Train Acc: 0.7208 || Val Loss: 1.8443 | Val Acc: 0.7015\n",
      "[Epoch 45/50] Train Loss: 1.4972 | Train Acc: 0.7216 || Val Loss: 1.8533 | Val Acc: 0.7014\n",
      "[Epoch 46/50] Train Loss: 1.4883 | Train Acc: 0.7227 || Val Loss: 1.8615 | Val Acc: 0.7018\n",
      "[Epoch 47/50] Train Loss: 1.4790 | Train Acc: 0.7233 || Val Loss: 1.8772 | Val Acc: 0.7013\n",
      "[Epoch 48/50] Train Loss: 1.4709 | Train Acc: 0.7240 || Val Loss: 1.8790 | Val Acc: 0.7015\n",
      "[Epoch 49/50] Train Loss: 1.4624 | Train Acc: 0.7250 || Val Loss: 1.8847 | Val Acc: 0.7018\n",
      "[Epoch 50/50] Train Loss: 1.4535 | Train Acc: 0.7261 || Val Loss: 1.8940 | Val Acc: 0.7012\n",
      "Training complete. Loading best model weights from checkpoint.\n",
      "Test Full-Sequence Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "###############################################################################\n",
    "# 1. Dataset and Collation\n",
    "###############################################################################\n",
    "class TokenSequenceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset for pre-tokenized sequences stored in memory. \n",
    "    Each sequence is a list of integer token IDs.\n",
    "\n",
    "    This class returns (input_seq, target_seq), where:\n",
    "      - input_seq = sequence[:-1]\n",
    "      - target_seq = sequence[1:]\n",
    "    \"\"\"\n",
    "    def __init__(self, sequences: List[List[int]]):\n",
    "        super().__init__()\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[List[int], List[int]]:\n",
    "        seq = self.sequences[idx]\n",
    "        # We shift to create input/target pairs for next-token prediction\n",
    "        input_seq = seq[:-1]\n",
    "        target_seq = seq[1:]\n",
    "        return input_seq, target_seq\n",
    "\n",
    "\n",
    "class PadCollator:\n",
    "    \"\"\"\n",
    "    A custom collator that pads input sequences to the same length in a batch,\n",
    "    creating attention masks and ensuring alignment of input/target sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, pad_token_id: int = 0):\n",
    "        self.pad_token_id = pad_token_id\n",
    "\n",
    "    def __call__(self, batch: List[Tuple[List[int], List[int]]]):\n",
    "        # Extract all input/target pairs\n",
    "        input_batch, target_batch = zip(*batch)\n",
    "\n",
    "        max_len = max(len(seq) for seq in input_batch)\n",
    "\n",
    "        padded_inputs = []\n",
    "        padded_targets = []\n",
    "        attention_masks = []\n",
    "\n",
    "        for inp, tgt in zip(input_batch, target_batch):\n",
    "            inp_len = len(inp)\n",
    "            pad_len = max_len - inp_len\n",
    "\n",
    "            # Pad inputs & targets\n",
    "            padded_inp = inp + [self.pad_token_id] * pad_len\n",
    "            padded_tgt = tgt + [self.pad_token_id] * pad_len\n",
    "\n",
    "            # Create attention mask: 1 for real tokens, 0 for padded\n",
    "            att_mask = [1] * inp_len + [0] * pad_len\n",
    "\n",
    "            padded_inputs.append(padded_inp)\n",
    "            padded_targets.append(padded_tgt)\n",
    "            attention_masks.append(att_mask)\n",
    "\n",
    "        # Convert to tensors\n",
    "        padded_inputs = torch.tensor(padded_inputs, dtype=torch.long)\n",
    "        padded_targets = torch.tensor(padded_targets, dtype=torch.long)\n",
    "        attention_masks = torch.tensor(attention_masks, dtype=torch.long)\n",
    "\n",
    "        return padded_inputs, padded_targets, attention_masks\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 2. Model Definition\n",
    "###############################################################################\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard sinusoidal positional encoding.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 50000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x shape: (batch, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        seq_len = x.size(1)\n",
    "        # Add positional encoding\n",
    "        x = x + self.pe[:, :seq_len]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class DecoderOnlyTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    A causal (decoder-only) Transformer model for next-token prediction.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        d_model: int = 256,\n",
    "        nhead: int = 4,\n",
    "        num_layers: int = 10,\n",
    "        dim_feedforward: int = 1024,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Token Embedding\n",
    "        self.token_emb = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout=dropout)\n",
    "\n",
    "        # Transformer Decoder Layers\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            activation='relu'\n",
    "        )\n",
    "        self.transformer_decoder = nn.TransformerDecoder(\n",
    "            decoder_layer, \n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        # Final projection to vocabulary\n",
    "        self.output_proj = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "        # Causal mask cache (for efficiency)\n",
    "        self.register_buffer(\"mask_cache\", None)\n",
    "\n",
    "    def _generate_causal_mask(self, sz: int, device: torch.device):\n",
    "        \"\"\"\n",
    "        Generates an upper-triangular causal mask to ensure each token \n",
    "        can only attend to preceding tokens (including itself).\n",
    "        \"\"\"\n",
    "        if (self.mask_cache is None) or (self.mask_cache.size(0) < sz):\n",
    "            mask = torch.triu(torch.ones(sz, sz, device=device), diagonal=1)\n",
    "            # Convert to boolean, True means \"block this position\"\n",
    "            mask = mask.bool()\n",
    "            self.mask_cache = mask\n",
    "        else:\n",
    "            mask = self.mask_cache[:sz, :sz]\n",
    "        return mask\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        input_ids: (batch, seq_len)\n",
    "        attention_mask: (batch, seq_len) => 1 for real tokens, 0 for pads\n",
    "\n",
    "        Returns:\n",
    "          logits of shape (batch, seq_len, vocab_size)\n",
    "        \"\"\"\n",
    "        device = input_ids.device\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "\n",
    "        # Generate token embeddings\n",
    "        tok_emb = self.token_emb(input_ids)  # (batch, seq_len, d_model)\n",
    "        # Add positional encoding\n",
    "        pos_emb = self.pos_encoder(tok_emb)\n",
    "\n",
    "        # Prepare the causal mask\n",
    "        causal_mask = self._generate_causal_mask(seq_len, device=device)  # (seq_len, seq_len)\n",
    "\n",
    "        # We also need to expand the attention_mask to shape (batch, 1, seq_len)\n",
    "        # so it can be broadcast to (batch, seq_len, seq_len).\n",
    "        # We'll turn 0 => True in the mask to block those positions.\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "        # So the final mask used by the decoder is (batch, seq_len, seq_len)\n",
    "        # with True where we want to block attention.\n",
    "        combined_mask = causal_mask.unsqueeze(0) | (extended_attention_mask == 0)\n",
    "\n",
    "        # Permute to fit PyTorch's (seq_len, batch, d_model)\n",
    "        pos_emb = pos_emb.permute(1, 0, 2)  # => (seq_len, batch, d_model)\n",
    "\n",
    "        # Decode (TransformerDecoder expects shape (seq_len, batch, d_model))\n",
    "        # The \"memory\" here is empty because we're using a decoder-only approach.\n",
    "        decoded = self.transformer_decoder(\n",
    "            pos_emb,\n",
    "            memory=torch.zeros(0, batch_size, self.d_model, device=device),  # dummy empty memory\n",
    "            tgt_mask=combined_mask[0],  # shape (seq_len, seq_len) for a single batch? We'll do a trick below.\n",
    "            # tgt_key_padding_mask=~attention_mask.bool()  # shape (batch, seq_len)\n",
    "             tgt_key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "\n",
    "        # NOTE: PyTorch's TransformerDecoder can’t directly handle a 3D mask. \n",
    "        # We used 'tgt_key_padding_mask' for pad tokens and 'tgt_mask' for causality. \n",
    "        # This approach merges them. If you have more advanced needs, you'd implement a custom layer or reshape.\n",
    "\n",
    "        # Undo the permute: (seq_len, batch, d_model) -> (batch, seq_len, d_model)\n",
    "        decoded = decoded.permute(1, 0, 2).contiguous()\n",
    "\n",
    "        # Project to vocab\n",
    "        logits = self.output_proj(decoded)  # (batch, seq_len, vocab_size)\n",
    "        return logits\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 3. Training / Validation / Testing\n",
    "###############################################################################\n",
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    optimizer: optim.Optimizer,\n",
    "    criterion: nn.CrossEntropyLoss,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Train for one epoch. Returns (avg_loss, approx_token_accuracy).\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets, attention_mask) in enumerate(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(inputs, attention_mask)  # (batch, seq_len, vocab_size)\n",
    "\n",
    "        # Reshape for loss: (batch*seq_len, vocab_size) vs (batch*seq_len)\n",
    "        vocab_size = logits.size(-1)\n",
    "        loss = criterion(logits.view(-1, vocab_size), targets.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate stats\n",
    "        running_loss += loss.item()\n",
    "        # Approximate token-level accuracy\n",
    "        preds = logits.argmax(dim=-1)  # (batch, seq_len)\n",
    "        mask_flat = attention_mask.view(-1).bool()\n",
    "        correct = (preds.view(-1)[mask_flat] == targets.view(-1)[mask_flat]).sum().item()\n",
    "        count = mask_flat.sum().item()\n",
    "        running_correct += correct\n",
    "        total_tokens += count\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    avg_acc = running_correct / total_tokens if total_tokens > 0 else 0.0\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "\n",
    "def validate(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    criterion: nn.CrossEntropyLoss,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Validate the model. Returns (avg_loss, approx_token_accuracy).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets, attention_mask in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "\n",
    "            logits = model(inputs, attention_mask)\n",
    "            vocab_size = logits.size(-1)\n",
    "            loss = criterion(logits.view(-1, vocab_size), targets.view(-1))\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Approximate token-level accuracy\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            mask_flat = attention_mask.view(-1).bool()\n",
    "            correct = (preds.view(-1)[mask_flat] == targets.view(-1)[mask_flat]).sum().item()\n",
    "            count = mask_flat.sum().item()\n",
    "            running_correct += correct\n",
    "            total_tokens += count\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    avg_acc = running_correct / total_tokens if total_tokens > 0 else 0.0\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "\n",
    "def test_sequence_accuracy(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Computes the fraction of sequences where the entire predicted sequence\n",
    "    matches the target sequence exactly. \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct_sequences = 0\n",
    "    total_sequences = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets, attention_mask in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "\n",
    "            logits = model(inputs, attention_mask)\n",
    "            preds = logits.argmax(dim=-1)  # (batch, seq_len)\n",
    "\n",
    "            # For each sequence in the batch, compare all tokens (where attention_mask=1).\n",
    "            for i in range(inputs.size(0)):\n",
    "                seq_mask = attention_mask[i].bool()\n",
    "                pred_seq = preds[i, seq_mask]\n",
    "                tgt_seq = targets[i, seq_mask]\n",
    "                total_sequences += 1\n",
    "                if torch.equal(pred_seq, tgt_seq):\n",
    "                    correct_sequences += 1\n",
    "\n",
    "    return correct_sequences / total_sequences if total_sequences > 0 else 0.0\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 4. Main Script\n",
    "###############################################################################\n",
    "def main():\n",
    "    # ---------------------------\n",
    "    # 4.1 Load Tokenized Data\n",
    "    # ---------------------------\n",
    "    json_path = \"dataset_encoded.json\"  # Change to your path if needed\n",
    "    with open(json_path, \"r\") as f:\n",
    "        token_data_dict = json.load(f)\n",
    "\n",
    "    # token_data_dict is assumed to be {filename: [list_of_token_ids], ...}\n",
    "    # Merge all token lists into one big list if needed, or keep them separate.\n",
    "    # We'll merge them for a single dataset:\n",
    "    all_sequences = []\n",
    "    for seq_list in token_data_dict.values():\n",
    "        # seq_list is presumably a list of ints\n",
    "        # Possibly it's a list of lists if you segmented each file. \n",
    "        # If needed, adapt to your structure. \n",
    "        # We'll assume it's a single list of token IDs per entry.\n",
    "        if isinstance(seq_list[0], int):\n",
    "            # single sequence\n",
    "            all_sequences.append(seq_list)\n",
    "        else:\n",
    "            # multiple sequences in a sub-list\n",
    "            all_sequences.extend(seq_list)\n",
    "\n",
    "    # Filter out any sequences shorter than 2 tokens (otherwise can't do input/target shift).\n",
    "    all_sequences = [seq for seq in all_sequences if len(seq) > 1]\n",
    "\n",
    "    MAX_CHUNK_LEN = 32  # or any reasonable max length\n",
    "    chunked_sequences = []\n",
    "\n",
    "    for seq_list in token_data_dict.values():\n",
    "        # If seq_list is a single sequence of IDs, chunk it\n",
    "        if isinstance(seq_list[0], int):\n",
    "            seq = seq_list\n",
    "            # Break the single seq into multiple chunks\n",
    "            for i in range(0, len(seq), MAX_CHUNK_LEN):\n",
    "                chunk = seq[i:i+MAX_CHUNK_LEN]\n",
    "                # We only keep chunks that have at least 2 tokens\n",
    "                if len(chunk) > 1:\n",
    "                    chunked_sequences.append(chunk)\n",
    "        else:\n",
    "            # If seq_list is already a list of sequences, chunk each\n",
    "            for seq in seq_list:\n",
    "                for i in range(0, len(seq), MAX_CHUNK_LEN):\n",
    "                    chunk = seq[i:i+MAX_CHUNK_LEN]\n",
    "                    if len(chunk) > 1:\n",
    "                        chunked_sequences.append(chunk)\n",
    "\n",
    "    all_sequences = chunked_sequences\n",
    "\n",
    "\n",
    "    # ---------------------------\n",
    "    # 4.2 Split into Train/Val/Test\n",
    "    # ---------------------------\n",
    "    random.shuffle(all_sequences)\n",
    "    dataset_size = len(all_sequences)\n",
    "    train_size = int(0.8 * dataset_size)\n",
    "    val_size = int(0.1 * dataset_size)\n",
    "    test_size = dataset_size - train_size - val_size\n",
    "\n",
    "    train_data, val_data, test_data = random_split(\n",
    "        all_sequences,\n",
    "        [train_size, val_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "\n",
    "    train_sequences = list(train_data)\n",
    "    val_sequences = list(val_data)\n",
    "    test_sequences = list(test_data)\n",
    "\n",
    "    # ---------------------------\n",
    "    # 4.3 Create Datasets & Loaders\n",
    "    # ---------------------------\n",
    "    pad_token_id = 0  # Adjust if your PAD token is something else\n",
    "    train_dataset = TokenSequenceDataset(train_sequences)\n",
    "    val_dataset = TokenSequenceDataset(val_sequences)\n",
    "    test_dataset = TokenSequenceDataset(test_sequences)\n",
    "\n",
    "    collator = PadCollator(pad_token_id=pad_token_id)\n",
    "    batch_size = 256\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collator)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collator)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collator)\n",
    "\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    print(\"Sample input shape:\", sample_batch[0].shape)\n",
    "    print(\"Sample target shape:\", sample_batch[1].shape)\n",
    "    print(\"Sample mask shape:\", sample_batch[2].shape)\n",
    "    print(\"Sample input:\", sample_batch[0][0][:10])  # First 10 tokens of first example\n",
    "    print(\"Sample target:\", sample_batch[1][0][:10])\n",
    "    print(\"Max token ID in input:\", sample_batch[0].max().item())\n",
    "    print(\"Max token ID in target:\", sample_batch[1].max().item())\n",
    "        # ---------------------------\n",
    "    # 4.4 Model, Optimizer, Loss\n",
    "    # ---------------------------\n",
    "    # You likely know your max vocab size from your tokenizer\n",
    "    # For example, if you used Byte-Level BPE or a custom mapping:\n",
    "    vocab_size = 2000  # <-- Replace with your actual vocabulary size\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = DecoderOnlyTransformer(\n",
    "        vocab_size=vocab_size,\n",
    "        d_model=256,          # Hidden dimension\n",
    "        nhead=8,              # Number of attention heads\n",
    "        num_layers=6,         # Number of transformer decoder layers\n",
    "        dim_feedforward=1024, # FFN dimension\n",
    "        dropout=0.1\n",
    "    )\n",
    "    model.to(device)    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-4)\n",
    "    pad_token_id=0\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_token_id)\n",
    "\n",
    "    # ---------------------------\n",
    "    # 4.5 Training Loop\n",
    "    # ---------------------------\n",
    "    epochs = 50\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # --- Train ---\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        # --- Validate ---\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "\n",
    "        print(f\"[Epoch {epoch}/{epochs}] \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} || \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Checkpoint if validation loss improves\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"transformer_model.pt\")\n",
    "            print(\"  (Best validation loss so far, saving model)\")\n",
    "\n",
    "    print(\"Training complete. Loading best model weights from checkpoint.\")\n",
    "    model.load_state_dict(torch.load(\"transformer_model.pt\"))\n",
    "\n",
    "    # ---------------------------\n",
    "    # 4.6 Evaluate on Test Set (Sequence Accuracy)\n",
    "    # ---------------------------\n",
    "    seq_acc = test_sequence_accuracy(model, test_loader, device)\n",
    "    print(f\"Test Full-Sequence Accuracy: {seq_acc:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After creating datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K_0': 295, 'X5': 592, 'X_6': 593, '317': 1037, 'I9': 270, 'D3': 148, 'P_4': 413, '094': 814, 'N7': 376, 'alpha': 691, 'D_5': 151, 'rho_': 1791, 'A_vec': 671, 'D4': 150, 'sqrt': 653, '382': 1102, 'L_2': 321, 'X8': 598, 'E-2': 1722, '497': 1217, 'K_4': 303, '762': 1482, 'D5': 152, 'J10': 294, '184': 904, '849': 1569, 'O_5': 393, '787': 1507, '973': 1693, 'D_6': 153, '933': 1653, ')*(': 1793, 'A9': 94, 'N0': 362, 'I_2': 255, '681': 1401, 'M_3': 345, 'N8': 378, 'U10': 536, 'lo': 1764, '841': 1561, '358': 1078, '029': 749, '913': 1633, 'P9': 424, 'l': 24, 'A_5': 85, 'U4': 524, 'X_7': 595, '449': 1169, '462': 1182, '+': 647, '565': 1285, '262': 982, 'W3': 566, '065': 785, 'F_10': 205, '976': 1696, '296': 1016, '627': 1347, '078': 798, '374': 1094, 'U_3': 521, '254': 974, '352': 1072, '487': 1207, '572': 1292, 'Z0': 626, '359': 1079, '532': 1252, 'E-6': 1726, 'N_10': 381, 'G_0': 207, 'Q0': 428, '459': 1179, '476': 1196, 'J7': 288, 'P_7': 419, 'T0': 494, 'X9': 600, 'P_5': 415, '641': 1361, '123': 843, '558': 1278, '835': 1555, '553': 1273, 'Z_10': 645, '567': 1287, 'c': 15, '046': 766, 'F_6': 197, '223': 943, '051': 771, '191': 911, 'X0': 582, 'E_7': 177, '047': 767, '111': 831, 'F5': 196, '199': 919, 'G_4': 215, 'M5': 350, '834': 1554, 'Y10': 624, '093': 813, 'Z9': 644, 'mom': 667, 'F_7': 199, 'Q_2': 431, '405': 1125, '884': 1604, '827': 1547, 'Q5': 438, '931': 1651, 'U7': 530, '190': 910, '263': 983, '671': 1391, '404': 1124, '613': 1333, '395': 1115, 'Pwr': 685, '875': 1595, '855': 1575, '226': 946, 'K_5': 305, '112': 832, '731': 1451, 'P_0': 405, '541': 1261, 'X_2': 585, '902': 1622, '789': 1509, '146': 866, 'nt': 1818, '326': 1046, '<PAD>': 0, '657': 1377, '017': 737, '906': 1626, 'X2': 586, '749': 1469, 'G10': 228, 'O10': 404, 'S_0': 471, '494': 1214, '(-((': 1834, '896': 1616, 'Z_7': 639, 'D8': 158, 'mo': 1816, '205': 925, '991': 1711, '110': 830, '014': 734, '319': 1039, '085': 805, '436': 1156, '056': 776, '370': 1090, '423': 1143, 'D_0': 141, '030': 750, '542': 1262, 'N_7': 375, '387': 1107, '847': 1567, '141': 861, '583': 1303, '1/4': 7, '303': 1023, '501': 1221, '036': 756, 'E_9': 181, 'V8': 554, 'b': 14, 'C_2': 123, '723': 1443, 'I0': 252, '337': 1057, '264': 984, ')+': 1827, '724': 1444, '830': 1550, '710': 1430, 'H_1': 231, '484': 1204, 'M_2': 343, 'U_4': 523, '016': 736, 'T1': 496, 'beta': 710, '228': 948, '747': 1467, '876': 1596, 'N_1': 363, '128': 848, '119': 839, '437': 1157, '632': 1352, '278': 998, '433': 1153, '=': 1747, '121': 841, '024': 744, 'I_3': 257, '243': 963, '635': 1355, '7': 72, '810': 1530, 'A7': 90, '921': 1641, '617': 1337, '521': 1241, 'T_8': 509, '786': 1506, 'P4': 414, 'A_8': 91, '610': 1330, 'W0': 560, 'G_5': 217, 'Y7': 618, '233': 953, 'P8': 422, 'Q_9': 445, 'D_8': 157, '105': 825, 'R10': 470, 'q2': 702, '365': 1085, '560': 1280, '704': 1424, 'Z_0': 625, '706': 1426, 'H_9': 247, 'a': 13, 'H': 46, '327': 1047, '691': 1411, '899': 1619, 'E_0': 163, 'W5': 570, '507': 1227, '891': 1611, '816': 1536, 'A': 39, 'V_9': 555, '845': 1565, 'U_6': 527, '963': 1683, 'J_10': 293, 'K8': 312, '478': 1198, '794': 1514, 'A5': 86, '418': 1138, '972': 1692, '137': 857, 'A_10': 95, 'g': 19, 'F_8': 201, 'W_8': 575, '718': 1438, '106': 826, '546': 1266, '683': 1403, '185': 905, 'A_0': 75, 'X6': 594, '=-': 1792, '161': 881, 'C_6': 131, '511': 1231, '010': 730, '720': 1440, '504': 1224, '764': 1484, '329': 1049, 'V10': 558, '533': 1253, '255': 975, 'E1': 166, 'R_8': 465, '048': 768, 'Y2': 608, '195': 915, '554': 1274, 'K6': 308, '235': 955, '331': 1051, 'u': 33, 'B': 40, '389': 1109, ')))*': 1831, '630': 1350, '890': 1610, '866': 1586, 'Q6': 440, '966': 1686, 'C9': 138, 'V9': 556, '953': 1673, 'Q1': 430, '524': 1244, '625': 1345, '160': 880, 'S_8': 487, '430': 1150, '040': 760, '159': 879, '619': 1339, '775': 1495, '737': 1457, '839': 1559, '353': 1073, '879': 1599, '1/6': 9, '793': 1513, 'M_0': 339, 'D_4': 149, '760': 1480, '280': 1000, '186': 906, 'E': 43, 'X4': 590, '402': 1122, '431': 1151, 'L_9': 335, 'B_1': 99, 'N4': 370, '454': 1174, '959': 1679, '665': 1385, '512': 1232, 'C_9': 137, 'qr': 1768, '929': 1649, '894': 1614, 'H5': 240, 'arctan': 662, 'ap': 1804, '480': 1200, 'D7': 156, 'D_10': 161, 'nh': 1817, 'p_d': 692, 'M1': 342, '407': 1127, 'W_1': 561, '045': 765, 'J3': 280, '))': 1754, '152': 872, '502': 1222, '095': 815, 'T8': 510, '928': 1648, 'L1': 320, 'S6': 484, 'S3': 478, '754': 1474, 'C': 41, 'G2': 212, '210': 930, '372': 1092, '409': 1129, 'W10': 580, '390': 1110, 'Int_0': 708, 'V3': 544, '621': 1341, '958': 1678, 'S2': 476, '344': 1064, 'C_5': 129, '322': 1042, 'Z_3': 631, 'B3': 104, 'W2': 564, 'U3': 522, '880': 1600, '363': 1083, '079': 799, 'A_': 1824, '169': 889, '859': 1579, 'N9': 380, 'Z2': 630, 'P3': 412, '154': 874, '938': 1658, '229': 949, '777': 1497, '750': 1470, '379': 1099, 'lta': 1814, 'Bx': 684, 'W_4': 567, 'N5': 372, 'Q_10': 447, '808': 1528, 'j': 22, 'lambd': 693, '950': 1670, 'cos': 656, '298': 1018, '238': 958, 'x2': 688, 'A10': 96, '411': 1131, '341': 1061, 'B0': 98, '413': 1133, '970': 1690, '348': 1068, 'G_3': 213, 'S_5': 481, '643': 1363, 'T4': 502, '600': 1320, 'C_10': 139, 'Q8': 444, '530': 1250, '601': 1321, '170': 890, '153': 873, 'ega': 1758, 'O5': 394, '782': 1502, '498': 1218, '734': 1454, 'P2': 410, 'E+0': 1731, '328': 1048, '743': 1463, 'N_5': 371, '796': 1516, 'B10': 118, 'Z7': 640, 'G4': 216, '446': 1166, '763': 1483, 'H6': 242, '008': 728, 'L_6': 329, '234': 954, 'J6': 286, '556': 1276, '531': 1251, '715': 1435, '916': 1636, '117': 837, 'D2': 146, 'H1': 232, 'H9': 248, 'I_0': 251, '843': 1563, '083': 803, 'D_9': 159, '688': 1408, 'A8': 92, 'G_6': 219, 'C7': 134, '361': 1081, 'B_3': 103, 'si': 1755, '655': 1375, '165': 885, '060': 780, 'arccos': 663, '042': 762, '467': 1187, 'C4': 128, '733': 1453, 'S_9': 489, '608': 1328, '162': 882, '144': 864, 'O_7': 397, '877': 1597, 'E10': 184, 'n_0': 682, '227': 947, 'kb': 719, 'K_1': 297, 'D_3': 147, '822': 1542, '840': 1560, '448': 1168, '708': 1428, '318': 1038, '156': 876, '021': 741, '187': 907, '321': 1041, 'U9': 534, 'R_3': 455, '552': 1272, 'Z_6': 637, '351': 1071, '220': 940, '802': 1522, '634': 1354, '509': 1229, 'F_3': 191, '149': 869, 'I8': 268, '516': 1236, '797': 1517, '888': 1608, '**': 651, 'C2': 124, 'B_6': 109, '597': 1317, '803': 1523, '670': 1390, '557': 1277, 'I10': 272, '883': 1603, '9': 74, '675': 1395, '380': 1100, 'V_3': 543, '722': 1442, '813': 1533, 'A_6': 87, '[DATA_END]': 4, '602': 1322, '831': 1551, 'A_2': 79, '355': 1075, '000': 720, '237': 957, '745': 1465, 'E_4': 171, 'V7': 552, 'kap': 1813, 'C5': 130, '246': 966, '212': 932, '366': 1086, 'K': 49, 'Z_4': 633, 'sin': 655, 'G1': 210, 't': 32, 'S9': 490, '163': 883, 'S_1': 473, '063': 783, 'A_1': 77, '738': 1458, 'arcsin': 661, 'S_2': 475, 'Jz': 681, '773': 1493, '049': 769, '707': 1427, '364': 1084, '442': 1162, 'O_10': 403, 'G6': 220, 'Y_8': 619, '))*': 1784, '772': 1492, '591': 1311, '637': 1357, 'U_10': 535, 'E+10': 1741, 'G': 45, '585': 1305, 'y2': 664, '920': 1640, 'chi': 695, 'S4': 480, '636': 1356, 'S': 57, '717': 1437, 'L_7': 331, '998': 1718, '025': 745, '620': 1340, '690': 1410, '776': 1496, 'O_6': 395, '988': 1708, 'B_4': 105, '403': 1123, '819': 1539, '659': 1379, 'K9': 314, 'A1': 78, '192': 912, '951': 1671, '709': 1429, '989': 1709, 'y': 37, 'C6': 132, '164': 884, '904': 1624, 'N_6': 373, 'O_2': 387, '274': 994, '145': 865, '208': 928, '219': 939, '267': 987, '3': 68, '528': 1248, '982': 1702, '222': 942, '393': 1113, 'G9': 226, '272': 992, '102': 822, 'p': 28, '667': 1387, 'Q_8': 443, 'Z8': 642, 'T_5': 503, '284': 1004, 'T_2': 497, '033': 753, 'K0': 296, '870': 1590, '534': 1254, 'U_1': 517, '376': 1096, 'M_9': 357, 'z2': 715, 'O1': 386, '937': 1657, '471': 1191, 'F_0': 185, '281': 1001, '721': 1441, 'Y3': 610, 'T_7': 507, 'P': 54, '678': 1398, 'C8': 136, '508': 1228, '193': 913, 'H2': 234, 'Z10': 646, 'I3': 258, '290': 1010, 'R2': 454, '908': 1628, 'K5': 306, 'R_5': 459, 'Q_1': 429, '652': 1372, 'm2': 677, 'C_3': 125, '242': 962, 'N6': 374, '579': 1299, '694': 1414, 'F9': 204, 'K7': 310, 'N_4': 369, '946': 1666, '526': 1246, '143': 863, '349': 1069, '943': 1663, '514': 1234, 'omega_': 1743, '712': 1432, 'ta': 1759, 'U_2': 519, '1/8': 11, '198': 918, 'k': 23, 'Y0': 604, '071': 791, 'ho': 1781, '218': 938, '986': 1706, '882': 1602, '493': 1213, '*': 649, '059': 779, 'J_4': 281, 'U2': 520, 'V': 60, '604': 1324, '984': 1704, '716': 1436, 'olt': 1799, '+(': 1786, 'L10': 338, '426': 1146, '980': 1700, '074': 794, 'B2': 102, '656': 1376, '097': 817, 'mma': 1789, ')**': 1771, '400': 1120, '310': 1030, 'silo': 1766, '286': 1006, '((': 1782, 'B_8': 113, '663': 1383, '804': 1524, 'J_2': 277, 'W_3': 565, '832': 1552, 'G_2': 211, '693': 1413, 'L_5': 327, '729': 1449, '247': 967, 'J8': 290, '(-(': 1833, '440': 1160, '735': 1455, '126': 846, '892': 1612, '975': 1695, '780': 1500, 'B6': 110, 'M6': 352, '088': 808, 'K2': 300, '))**': 1794, 'V_0': 537, 'B_7': 111, 'n_rho': 700, '392': 1112, '140': 860, 'F': 44, '176': 896, 'C3': 126, '474': 1194, 'theta1': 669, '))-': 1787, '026': 746, '850': 1570, '684': 1404, '587': 1307, 'M_10': 359, '350': 1070, 'U0': 516, '672': 1392, 'E_10': 183, 'B_2': 101, 'ch': 1796, 'sigma': 711, 'E-7': 1727, '420': 1140, '515': 1235, '568': 1288, '955': 1675, '005': 725, '746': 1466, '465': 1185, 'Q_3': 433, 'E+5': 1736, 'X3': 588, '308': 1028, 'R_0': 449, '862': 1582, '654': 1374, 'P6': 418, '020': 740, 'P_1': 407, 'J_3': 279, 'X': 62, 'ft': 1809, '381': 1101, 'N3': 368, 'R6': 462, 'E-10': 1730, 'J': 48, 'F0': 186, 'K4': 304, '898': 1618, 'B8': 114, '962': 1682, '836': 1556, '297': 1017, '935': 1655, 'L_4': 325, 'R1': 452, 'heta': 1763, '468': 1188, 'U': 59, 'Y1': 606, '360': 1080, 'E_5': 173, '680': 1400, '179': 899, 'G0': 208, 'ec': 1807, '(-': 1785, 'rho_c_': 1745, '027': 747, 'G5': 218, 'gamma': 680, '345': 1065, '618': 1338, 'D6': 154, '505': 1225, '325': 1045, '375': 1095, 'K_10': 315, 'U8': 532, '795': 1515, 'J4': 282, 'H_2': 233, '922': 1642, 'Ef': 694, 'lam': 1815, 'P1': 408, '714': 1434, '826': 1546, 'O7': 398, 'S8': 488, 'E+1': 1732, 'Q4': 436, 'J_9': 291, '689': 1409, '771': 1491, 'R_6': 461, 'H_10': 249, '336': 1056, '924': 1644, '490': 1210, '034': 754, '985': 1705, '130': 850, '148': 868, '485': 1205, '967': 1687, 'rift': 1820, '638': 1358, '061': 781, 'M8': 356, '158': 878, '987': 1707, '259': 979, '520': 1240, 'Z3': 632, '412': 1132, '388': 1108, 'x': 36, 'Y_3': 609, '895': 1615, '122': 842, '824': 1544, 'ex': 1772, '964': 1684, 'V_6': 549, 'C_0': 119, '779': 1499, '873': 1593, ')))': 1830, '595': 1315, '867': 1587, '857': 1577, 'I_10': 271, 'X_5': 591, 'R_9': 467, '547': 1267, '189': 909, '265': 985, ')': 1751, 'T3': 500, '549': 1269, '555': 1275, '473': 1193, 'ift': 1811, 'F4': 194, 'Z_9': 643, 'V0': 538, 'Volt': 679, 'I_6': 263, '151': 871, '050': 770, '648': 1368, '316': 1036, 'I1': 254, '954': 1674, 'E-5': 1725, '428': 1148, '075': 795, '559': 1279, 'L_0': 317, '369': 1089, 'z': 38, '863': 1583, 'M_7': 353, '901': 1621, '266': 986, '385': 1105, 'D_2': 145, '424': 1144, '828': 1548, '221': 941, '785': 1505, '354': 1074, 'CO': 1800, 'R_1': 451, 'T_1': 495, '))+': 1829, 'F6': 198, 'L5': 328, 'O3': 390, '357': 1077, 'c_0': 1788, '188': 908, '592': 1312, 'O8': 400, '742': 1462, '175': 895, 'H10': 250, '023': 743, '778': 1498, '623': 1343, 'S0': 472, 'P5': 416, '871': 1591, '519': 1239, '569': 1289, '993': 1713, 'M3': 346, 'I5': 262, '662': 1382, '770': 1490, 'Q': 55, '614': 1334, '748': 1468, 'Y_0': 603, 'x3': 713, '701': 1421, '628': 1348, '003': 723, '517': 1237, '941': 1661, '703': 1423, 'T2': 498, '294': 1014, '936': 1656, 'E+9': 1740, '609': 1329, '347': 1067, '695': 1415, 'I_': 1748, 'J_0': 273, '477': 1197, '[ROW_SEP]': 3, 'O4': 392, '696': 1416, 'L8': 334, 'C_8': 135, 'm1': 687, 'E_6': 175, ')))**': 1832, '217': 937, 'f': 18, 'R9': 468, 'N1': 364, 'X_0': 581, '499': 1219, '311': 1031, '292': 1012, 'S5': 482, 'L4': 326, 'n_': 1749, '232': 952, 'U_8': 531, '124': 844, 'D_1': 143, 'theta2': 701, '965': 1685, '755': 1475, '817': 1537, '194': 914, 'V_4': 545, '315': 1035, '846': 1566, 'Y9': 622, 'E+8': 1739, '540': 1260, '981': 1701, '422': 1142, '669': 1389, 'T_9': 511, 'V_8': 553, 'K_6': 307, '679': 1399, '682': 1402, '231': 951, 'd': 16, '561': 1281, 'T_0': 493, 'H_7': 243, '340': 1060, '564': 1284, 'V_7': 551, 'k_': 1812, '182': 902, '127': 847, '624': 1344, '914': 1634, 'z1': 678, '611': 1331, '640': 1360, 'B_10': 117, '108': 828, '450': 1170, 'A3': 82, 'Y_9': 621, '067': 787, 'By': 718, '057': 777, '287': 1007, '-': 648, 'H_6': 241, '649': 1369, '261': 981, '<UNK>': 1, '104': 824, 'delta': 699, 'C10': 140, 'S10': 492, 'I6': 264, 'G_7': 221, '821': 1541, '900': 1620, 'kappa': 673, 'Y_6': 615, '335': 1055, '488': 1208, '983': 1703, 'E-0': 1720, 'R': 56, '343': 1063, '070': 790, 'I7': 266, '118': 838, 'pr': 716, 'P10': 426, '410': 1130, '-(': 1801, '687': 1407, '453': 1173, '944': 1664, 'O_8': 399, '116': 836, 'Y8': 620, '759': 1479, '_': 1752, 'W6': 572, 'Y_4': 611, '383': 1103, 'vec': 1822, 'X_9': 599, 'P0': 406, 'Q_7': 441, '291': 1011, 'Q10': 448, 'V1': 540, 'F7': 200, '084': 804, '384': 1104, '837': 1557, '396': 1116, 'M_8': 355, '732': 1452, '994': 1714, '270': 990, '249': 969, 'Z4': 634, '571': 1291, '419': 1139, 'I_1': 253, '677': 1397, 'S1': 474, 'W1': 562, '269': 989, 'rho': 705, '211': 931, 'E3': 170, '919': 1639, '952': 1672, '214': 934, 'K_7': 309, '961': 1681, 'H3': 236, '979': 1699, 'P_2': 409, 'S_7': 485, '606': 1326, 'H0': 230, ')*': 1765, '038': 758, 'V6': 550, '598': 1318, '651': 1371, '700': 1420, '202': 922, '949': 1669, '098': 818, '216': 936, 'S_10': 491, 'D1': 144, '644': 1364, 'ing': 1835, 'L3': 324, 'M_5': 349, '889': 1609, 'B9': 116, '109': 829, 'e': 17, 'spr': 1821, 'epsilo': 1767, 'Y_5': 613, 'L9': 336, '791': 1511, 'Int': 658, 'S_6': 483, 'F3': 192, 'tanh': 659, '758': 1478, 'x1': 714, '969': 1689, '429': 1149, '666': 1386, 'U_0': 515, '761': 1481, 's': 31, '660': 1380, '271': 991, '324': 1044, 'h': 20, '781': 1501, '584': 1304, 'L': 50, 'Q_5': 437, 'ln': 657, '1/2': 5, 'H_0': 229, 'co': 1773, '523': 1243, '996': 1716, '563': 1283, 'ar': 1795, '258': 978, 'U5': 526, '728': 1448, 'sigma_den': 707, '586': 1306, '183': 903, 'E+7': 1738, 'I_8': 267, 'W': 61, 'Nn': 666, ')+(': 1828, '926': 1646, 'V_1': 539, 'J_6': 285, 'q': 29, '522': 1242, 'P_6': 417, 'S_3': 477, 'T9': 512, 'O_3': 389, '629': 1349, '230': 950, '736': 1456, 'G_1': 209, '574': 1294, 'L7': 332, '947': 1667, '447': 1167, '268': 988, 'M10': 360, ')/': 1779, '483': 1203, 'Z6': 638, '055': 775, '131': 851, '727': 1447, 'D9': 160, '910': 1630, '858': 1578, '039': 759, 'K10': 316, '698': 1418, 'A_4': 83, '492': 1212, '028': 748, 'J0': 274, '668': 1388, 'M_6': 351, 'O0': 384, 'M2': 344, '945': 1665, '417': 1137, '[COL_SEP]': 2, '129': 849, 'm': 25, 'd1': 683, 'log': 660, '881': 1601, 'T10': 514, 'csin': 1797, 'A_7': 89, '252': 972, '842': 1562, '893': 1613, 'i': 21, '332': 1052, '044': 764, 'P_10': 425, 'L_1': 319, 'sqr': 1769, '285': 1005, 'pa': 1819, '646': 1366, 'L_3': 323, '1/3': 6, '658': 1378, '527': 1247, '103': 823, 'E8': 180, '496': 1216, 'mu_d': 1825, 'I4': 260, 'r1': 686, '995': 1715, '177': 897, 'O_9': 401, '253': 973, '209': 929, '768': 1488, '452': 1172, '391': 1111, '912': 1632, '753': 1473, '856': 1576, '1': 66, '653': 1373, 'N_0': 361, '590': 1310, '425': 1145, '960': 1680, '368': 1088, 'mu': 690, 'K_9': 313, '299': 1019, '814': 1534, '155': 875, 'Y': 63, 'COS': 1742, '256': 976, '603': 1323, 'T7': 508, '022': 742, 'P_3': 411, 'A_9': 93, '765': 1485, '582': 1302, 'N_2': 365, 'H4': 238, 'V_10': 557, 'M7': 354, 'B1': 100, '825': 1545, '999': 1719, '443': 1163, '853': 1573, 'Y4': 612, '338': 1058, 'P7': 420, '077': 797, '903': 1623, '293': 1013, '536': 1256, '692': 1412, '096': 816, 'E-9': 1729, '642': 1362, '236': 956, '932': 1652, '037': 757, '719': 1439, 'F10': 206, '035': 755, 'V4': 546, '434': 1154, '069': 789, 'S_4': 479, '548': 1268, '399': 1119, 'Y_7': 617, 'pha': 1778, '872': 1592, 'F2': 190, 'R0': 450, '306': 1026, 'E6': 176, 'J1': 276, 'O': 53, 'rho_c_0': 665, '475': 1195, 'F_5': 195, 'F_1': 187, '456': 1176, 'mu_drift': 672, 'H_5': 239, 'W_9': 577, '482': 1202, '064': 784, 'E+6': 1737, '142': 862, '578': 1298, '090': 810, 'E_1': 165, '092': 812, 'G7': 222, '588': 1308, '874': 1594, 'W4': 568, '942': 1662, '997': 1717, '240': 960, 'Y_2': 607, '518': 1238, '181': 901, '860': 1580, '593': 1313, '260': 980, '427': 1147, '581': 1301, '815': 1535, 'E0': 164, 'W8': 576, 'lt': 1798, '408': 1128, 'n': 26, 'L6': 330, 'H_4': 237, 'gma': 1780, '276': 996, '086': 806, '397': 1117, 'E_': 1790, 'T_4': 501, 'W_7': 573, '869': 1589, '868': 1588, '576': 1296, '114': 834, 'W_10': 579, 'I_7': 265, '957': 1677, 'y3': 670, '697': 1417, 'H_3': 235, 'mob': 706, '304': 1024, '633': 1353, '072': 792, 'omega': 668, 'ma': 1774, '307': 1027, '009': 729, '923': 1643, 'W_0': 559, '506': 1226, '705': 1425, '605': 1325, '373': 1093, '562': 1282, 'K1': 298, '470': 1190, '371': 1091, '445': 1165, '091': 811, 'D': 42, '934': 1654, '599': 1319, '829': 1549, 'X10': 602, '099': 819, 'A2': 80, '833': 1553, 'P_8': 421, 'Q9': 446, '288': 1008, 'I2': 256, '073': 793, 'E+3': 1734, 'w': 35, '068': 788, 'T_10': 513, 'U_7': 529, '087': 807, 'N_9': 379, 'R7': 464, '766': 1486, '686': 1406, '767': 1487, '466': 1186, 'J_7': 287, 'B_9': 115, '631': 1351, 'J9': 292, '166': 886, 'R5': 460, '977': 1697, '865': 1585, 'X7': 596, '012': 732, '100': 820, '115': 835, '992': 1712, '783': 1503, '844': 1564, '5': 70, 'in': 1810, '167': 887, 'M_4': 347, 'S7': 486, '394': 1114, 'X_10': 601, '300': 1020, 'M0': 340, 'O_1': 385, '011': 731, '739': 1459, 'Z1': 628, 'd2': 704, '323': 1043, '301': 1021, '(': 1750, 'R_7': 463, 'Z_8': 641, 'L_8': 333, '275': 995, 'X_4': 589, '076': 796, '113': 833, '197': 917, '711': 1431, 'E+2': 1733, '139': 859, '607': 1327, '2': 67, '132': 852, 'L0': 318, 'R_2': 453, '543': 1263, '589': 1309, 'E-1': 1721, '664': 1384, 'Z_2': 629, '1/5': 8, 'E4': 172, '661': 1381, '500': 1220, 'E_2': 167, '464': 1184, 'P_9': 423, '818': 1538, 'k_spr': 1836, '489': 1209, 'J_5': 283, '138': 858, 'm_': 1744, 'E_n': 703, 'Q_6': 439, 'sigma_d': 1826, '861': 1581, '513': 1233, '432': 1152, 'q1': 676, 'V_2': 541, 'y1': 674, '537': 1257, '241': 961, 'T_6': 505, '978': 1698, 'E-8': 1728, '282': 1002, '639': 1359, '213': 933, '313': 1033, 'Z': 64, 'Int_': 1746, 'Y6': 616, '245': 965, 'H_8': 245, '510': 1230, 'G_8': 223, 'M4': 348, 'B_5': 107, '107': 827, 'M': 51, '438': 1158, '864': 1584, '971': 1691, '333': 1053, '356': 1076, 'k_spring': 689, '741': 1461, '573': 1293, '334': 1054, '_0': 1770, '135': 855, '806': 1526, 'r2': 696, '907': 1627, 'V5': 548, '172': 892, '439': 1159, '367': 1087, '174': 894, '180': 900, '550': 1270, 'am': 1803, '250': 970, 'Y_10': 623, 'B7': 112, '204': 924, 'D0': 142, '650': 1370, 'Q_0': 427, '854': 1574, 'V2': 542, 'O_0': 383, '125': 845, '101': 821, '805': 1525, 'K_8': 311, 'C_7': 133, '206': 926, 'I': 47, 'T5': 504, '927': 1647, '486': 1206, '790': 1510, 'J_8': 289, 'E2': 168, 'U_9': 533, '136': 856, 'ep': 1762, '529': 1249, '013': 733, '203': 923, 'Q2': 432, 'X1': 584, '622': 1342, '918': 1638, 'T_3': 499, 'W_6': 571, '458': 1178, '940': 1660, '207': 927, '726': 1446, '339': 1059, 'O6': 396, 'J5': 284, '171': 891, 'R8': 466, '031': 751, '472': 1192, '224': 944, '406': 1126, 'eta': 1761, '4': 69, 'E_8': 179, 'L2': 322, '006': 726, 'U_5': 525, 'O2': 388, '491': 1211, 'R4': 458, '823': 1543, 'B_0': 97, '1/9': 12, '302': 1022, 'I_5': 261, '616': 1336, 'B4': 106, '535': 1255, 'epsilon': 698, '273': 993, 'K_3': 301, '545': 1265, '811': 1531, '244': 964, '295': 1015, '544': 1264, 'E7': 178, 'Z_5': 635, '0': 65, '058': 778, '820': 1540, '852': 1572, 'de': 1806, 'F_2': 189, '685': 1405, '566': 1286, '215': 935, 'omega_0': 717, '054': 774, 'E5': 174, 'C_4': 127, '/((': 1802, 'G_10': 227, '081': 801, '8': 73, '/': 650, '043': 763, '538': 1258, 'ha': 1777, 'X_8': 597, '911': 1631, 'K_2': 299, 'X_1': 583, '457': 1177, 'wr': 1823, 'A6': 88, '792': 1512, 'bd': 1805, 'Q3': 434, '441': 1161, '784': 1504, 'Y5': 614, '314': 1034, '398': 1118, '257': 977, 'O_4': 391, '596': 1316, 'W7': 574, 'g_': 675, 'M_1': 341, 'Q_4': 435, 'Bz': 712, 'E_3': 169, '342': 1062, '479': 1199, 'E-4': 1724, '575': 1295, '362': 1082, '019': 739, '414': 1134, 'R_10': 469, '751': 1471, '838': 1558, '740': 1460, '915': 1635, '416': 1136, '015': 735, '377': 1097, '469': 1189, '225': 945, 'Z_1': 627, '150': 870, 'E9': 182, 'pi': 654, '594': 1314, '878': 1598, '066': 786, '577': 1297, '930': 1650, '495': 1215, '848': 1568, '460': 1180, '551': 1271, '645': 1365, '798': 1518, '168': 888, '503': 1223, 'exp': 652, 'T': 58, ')/(': 1783, 'F1': 188, '725': 1445, 'G8': 224, 'K3': 302, '968': 1688, '082': 802, 'U6': 528, '463': 1183, '757': 1477, '279': 999, '401': 1121, 'J2': 278, 'ga': 1757, '713': 1433, 'm_0': 709, '909': 1629, '157': 877, 'al': 1776, '002': 722, 'B5': 108, '173': 893, '774': 1494, '809': 1529, 'Z5': 636, 'theta': 697, 'T6': 506, '147': 867, '756': 1476, '939': 1659, '752': 1472, 'D10': 162, '346': 1066, '386': 1106, '800': 1520, '580': 1300, '886': 1606, '053': 773, 'F_9': 203, '801': 1521, '120': 840, '744': 1464, '674': 1394, 'C_1': 121, '570': 1290, '676': 1396, '539': 1259, '134': 854, '248': 968, '041': 761, 'N_3': 367, '133': 853, '007': 727, '812': 1532, '699': 1419, 'R3': 456, '277': 997, '925': 1645, 'J_1': 275, '615': 1335, '001': 721, '*(': 1760, 'A_3': 81, 'W_2': 563, '/(': 1753, '6': 71, '887': 1607, '312': 1032, 'A0': 76, 'r': 30, '851': 1571, '702': 1422, 'U1': 518, 'O9': 402, 'v': 34, '974': 1694, '885': 1605, '673': 1393, 'H7': 244, '320': 1040, 'C0': 120, 'C1': 122, '289': 1009, '062': 782, '612': 1332, '799': 1519, 'Q7': 442, 'W9': 578, '239': 959, '196': 916, 'X_3': 587, '525': 1245, '730': 1450, 'L_10': 337, 'G3': 214, '_d': 1775, 'D_7': 155, 'E+4': 1735, 'N_8': 377, '200': 920, '451': 1171, 'F8': 202, '283': 1003, '309': 1029, 'N': 52, 'A4': 84, '032': 752, '178': 898, '330': 1050, '251': 971, '378': 1098, '435': 1155, '004': 724, '905': 1625, '990': 1710, '080': 800, '626': 1346, '455': 1175, 'N10': 382, '788': 1508, 'G_9': 225, 'F_4': 193, 'H8': 246, 'Y_1': 605, '415': 1135, '305': 1025, 'om': 1756, '956': 1676, '201': 921, 'o': 27, '444': 1164, 'I_4': 259, 'R_4': 457, '089': 809, '647': 1367, 'M9': 358, 'en': 1808, '948': 1668, 'N2': 366, 'V_5': 547, '1/7': 10, 'W_5': 569, '461': 1181, '421': 1141, '897': 1617, 'I_9': 269, '052': 772, '917': 1637, '769': 1489, '481': 1201, '018': 738, '807': 1527, 'E-3': 1723}\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "tokenizer = Tokenizer.from_file(\"my_tokenizer.json\")\n",
    "print(tokenizer.get_vocab())  # Ensure numeric tokens like '+', '-', 'E+3' etc. are there\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.token_to_id(\"[DATA_END]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harshenv",
   "language": "python",
   "name": "harshenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
